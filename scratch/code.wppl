// code for chapt 3

var ash = function(){assert.ok(false, 'assert halt');};


var printERP = function(x) {
  var erpValues = sort(x.support(), undefined, function(v){return -x.score([], v);});
  map(
    function(v){
      var prob = Math.exp(x.score([], v));
      if (prob > 0.0){
        console.log(JSON.stringify(v) + ': ' + prob.toFixed(5));
      }
    },
    erpValues);
};

var argMax = function(f,ar){return maxWith(f,ar)[0]}

                     
var firstExample = function(){

  var transition = function(state, action){
    return action=='italian' : 'pizza' : 'no pizza';
  };
  
  var utility = function(state){
    return state == 'pizza' ? 1 : 0;
  };
  
  var maxAgent = function(){
    return utility(transition('italian')) > utility(transition('french')) ? 'italian' : 'french'
  }
  

  // planning as inference agent
  
  var agent = function(){
    return Enumerate(function(){
      var action = uniformDraw(['french', 'italian'])
      condition( transition(action) == 'pizza' )
    return action
    })
  };
  
  
  // probabilistic outcomes
  var transition = function(state, action){
    var nextStates = ['bad', 'good', 'spectacular'];
    if (action=='italian'){ 
      return categorical( [0.2, 0.6, 0.2], nextStates );
    } else {
      return categorical( [0.05, 0.9, 0.05], nextStates );
  };

  var utility = function(transition){
    var table = {bad: -10, good: 6, spectacular:8};
    return table[transition];
  };

  var maxEUAgent = function(){
    var EU = function(action){
      return expectation( Enumerate( function(){
        return utility(transition(action));
      }));
    };
    return argMax( EU, ['italian', 'french'] );
  };
    
 
  var conditionAgent = function(){
    return Enumerate(function(){
      
      var action = uniformDraw(['french', 'italian'])

      var EU = function(action){
        return expectation( Enumerate( function(){
          return utility(transition(action));
        }));
      };
      condition( EU(action) > 4 );
      return action;
    })
  };

  var alpha = 1;

  var softMaxAgent = function(){
    return Enumerate(function(){
      
      var action = uniformDraw(['french', 'italian']);
      
      var EU = function(action){
        return expectation( Enumerate( function(){
          return utility(transition(action));
        }));
      };
      factor( alpha*EU(action) )
      
      return action;
    })
  };

  console.log('maxEU', maxEUAgent() );
  printERP(conditionAgent()); //
  printERP(softMaxAgent()); //

  console.log('cond', conditionAgent(), softMaxAgent());
  ash();


  
  
  return {maxAgent: maxAgent(), agent: sample(agent())}
}


var secondExample = function(){
  // multi-attribute: find best restaurant, given features
  
  var consequence = function(action){
    var restaurantToVector = { 1: [2, 9, 9], // [price, food, location]
                               2: [4, 6, 7],
                               3: [9, 4, 7] }
    return restaurantToVector[action]
  }
  

  var utility = function(vector){
    return vector[0]*0.8 + vector[1]*0.9 + vector[2]*0.5
  }
  
  var argMax = function(f,ar){return maxWith(f,ar)[0]}
  
  
  var maxAgent = function(){
    return argMax( function(action){return utility(consequence(action))}, [1,2,3])
  }

  var agent = function(){
    return Enumerate(function(){
      var action = uniformDraw([1,2,3])
      condition( utility(consequence(action)) > 13 )
    return action
    })
  }

  return {maxAgent: maxAgent(), agent: [sample(agent()), sample(agent()), sample(agent()), sample(agent())]}
}

// example with two actions. agent calls function 'agent at next timestep'. agent at timestep1 is agent's model of itself.
// maybe its wrong. well see both cases later. could illustrate failure of this explicitly in biases section by
// showing the two different models. 



console.log('ag', firstExample(), secondExample())
                                                
  


