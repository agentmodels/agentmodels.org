var world = restaurantChoiceMDP;
var feature = world.feature;

var utilityTablePrior = function(){
  var foodValues = [0,1,2,3];
  var timeCostValues = [-0.1, -0.3, -0.6, -1];
  var donut = uniformDraw(foodValues);

  return {'Donut N': donut,
          'Donut S': donut,
          Veg: uniformDraw(foodValues),
          Noodle: uniformDraw(foodValues),
          timeCost: uniformDraw(timeCostValues)};
};
var alphaPrior = function(){return uniformDraw([.1,1,10,100]);};

var posterior = function(observedStateActionSequence){
  return Enumerate( function() {
    var utilityTable = utilityTablePrior();
    var alpha = alphaPrior();
	var logAlpha = Math.log10(alpha);
	var timeCost = utilityTable.timeCost;
    var params = {utility: mdpTableToUtilityFunction(utilityTable, feature),
		  alpha: alpha};
    var agent = makeMDPAgent(params, world);
    var act = agent.act;

    var donutBest = utilityTable['Donut N'] >= utilityTable['Veg']
	  && utilityTable['Donut N'] >= utilityTable['Noodle'];

    // For each observed state-action pair, compute likekihood of action
    map( function(stateAction){
      factor( act(stateAction[0]).score( [], stateAction[1]) );
    }, observedStateActionSequence );

    return {donutBest: donutBest, logAlpha: logAlpha,
		    timeCost: timeCost};
  });
};


var observedStateActionSequence = locationsToStateActions(restaurantNameToPath.donutSouth);

// these ERPs do not print for some reason
// TODO: fix this
// viz.vegaPrint(posterior(observedStateActionSequence.slice(0,1)));
// viz.vegaPrint(posterior(observedStateActionSequence.slice(0,2)));
viz.vegaPrint(posterior(observedStateActionSequence.slice(0,3)));
